{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NQR7YYGG24EC"
   },
   "outputs": [],
   "source": [
    "# for loading/processing the images\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils  import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# models\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn as sk\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "from google.colab import drive\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sdqBQ6-ZStN",
    "outputId": "f4d15277-ba3b-415d-cc01-7e783a633925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANnt8GQEYSSt"
   },
   "source": [
    "###Paso 1\n",
    "Cargo imágenes del zip y las preproceso con el modelo preentrenado quedandome con la capa -2, para obtener las features capturadas pr el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeUzb5yY3DUK",
    "outputId": "cba612a6-b384-4588-eaaf-6e3f16bde299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "ARCHIVO = ('/content/drive/MyDrive/DMCT/Rice_Dataset.zip')\n",
    "\n",
    "fotos_zip = ZipFile(ARCHIVO)\n",
    "lista_imágenes = fotos_zip.namelist()\n",
    "serie_imagenes = pd.Series(lista_imágenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpL5AApp24ED"
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJo5waeg24ED"
   },
   "outputs": [],
   "source": [
    "def get_labels_and_paths(input_folder):\n",
    "   return sorted([(dp.split(\"/\")[1],os.path.join(dp, f)) for dp, dn, filenames in os.walk(input_folder) for f in filenames if os.path.splitext(f)[1] == '.jpg'])\n",
    "\n",
    "\n",
    "def extract_features(file, model, zip):\n",
    "\n",
    "    # levanta imagen como array 224x224\n",
    "    img = load_img(BytesIO(zip.read(file)) , target_size=(224,224))\n",
    "    # convierte img a numpy array (originalmente es 'PIL.Image.Image')\n",
    "    img = np.array(img)\n",
    "    # reshape para tener formato necesario para el modelo (num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3)\n",
    "    # prepara imagen para modelo (función de keras)\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # extrae features\n",
    "    features = model.predict(imgx, use_multiprocessing=True, verbose=0)\n",
    "    return features\n",
    "\n",
    "from tqdm import tqdm\n",
    "def preprocess(names_and_paths, model, zip):\n",
    "    preprocessed_data = {}\n",
    "    for name, path in tqdm(names_and_paths):\n",
    "    #   print(path)\n",
    "      featuress = extract_features(path, model, zip)\n",
    "      preprocessed_data[path] = {'label':name,\n",
    "                    'features':featuress}\n",
    "      #print(f\"Extracción features de {path}\")\n",
    "    return preprocessed_data\n",
    "\n",
    "\n",
    "# function that lets you view a cluster (based on identifier)\n",
    "def view_cluster(gps,cluster):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = gps\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 10:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 10\")\n",
    "        files = files[:9]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(1,10,index+1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Cluster n:' + str(cluster))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uctLSmfv7NWp"
   },
   "outputs": [],
   "source": [
    "ser_arb = serie_imagenes[serie_imagenes.str.startswith('Rice_Image_Dataset/Arborio/A')]\n",
    "ser_bas = serie_imagenes[serie_imagenes.str.startswith(('Rice_Image_Dataset/Basmati/b','Rice_Image_Dataset/Basmati/B'))]\n",
    "ser_ips = serie_imagenes[serie_imagenes.str.startswith('Rice_Image_Dataset/Ipsala/I')]\n",
    "ser_jas = serie_imagenes[serie_imagenes.str.startswith('Rice_Image_Dataset/Jasmine/J')]\n",
    "ser_kar = serie_imagenes[serie_imagenes.str.startswith('Rice_Image_Dataset/Karacadag/K')]\n",
    "del lista_imágenes, serie_imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVC-bT6H24ED"
   },
   "outputs": [],
   "source": [
    "def label_path(label, paths):\n",
    "    return [(label, path) for path in paths]\n",
    "\n",
    "#names_and_paths = get_labels_and_paths(input_folder=ARCHIVO)\n",
    "names_and_paths = (label_path('Arborio', ser_arb) +\n",
    "                    label_path('Basmati', ser_bas) +\n",
    "                    label_path('Ipsala', ser_ips) +\n",
    "                    label_path('Jasmine', ser_jas) +\n",
    "                    label_path('Karacadag', ser_kar))\n",
    "\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "\n",
    "# Contar las clases\n",
    "class_counts = Counter(item[0] for item in names_and_paths)\n",
    "\n",
    "# Calcular la cantidad mínima de elementos por clase\n",
    "min_count = 30\n",
    "\n",
    "# Crear una lista de elementos por clase\n",
    "grouped_data = {key: [item for item in names_and_paths if item[0] == key] for key in class_counts.keys()}\n",
    "\n",
    "# Tomar una muestra estratificada\n",
    "stratified_sample = []\n",
    "for key, group in grouped_data.items():\n",
    "    random.shuffle(group)  # Mezcla los elementos para obtener una muestra aleatoria\n",
    "    stratified_sample.extend(group[:min_count])  # Agrega la misma cantidad de elementos por clase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjImB4GK24EE",
    "outputId": "54b73d46-4559-4e0d-cb00-04cdb6451912"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8068/50000 [17:10<3:09:35,  3.69it/s]"
     ]
    }
   ],
   "source": [
    "data_dict = preprocess(names_and_paths=stratified_sample, model=model, zip=fotos_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4bfzhw224EE"
   },
   "outputs": [],
   "source": [
    "labels =  [data_dict[k]['label'] for k in data_dict.keys()]\n",
    "features = [data_dict[k]['features'][0] for k in data_dict.keys()]\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoRBppWsppOs"
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(features)\n",
    "df_features.to_csv('/content/drive/MyDrive/DMCT/features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykUefBrbc-2l"
   },
   "outputs": [],
   "source": [
    "fotos_zip.close()\n",
    "del fotos_zip"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
