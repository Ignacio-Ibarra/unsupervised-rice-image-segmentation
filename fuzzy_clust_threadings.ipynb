{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignacio-Ibarra/unsupervised-rice-image-segmentation/blob/main/fuzzy_clust_threadings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HJ_bX4_lFpg",
        "outputId": "38d260a9-3ae5-4b16-927b-88919eee7cd1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
        "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
        "\n",
        "# Normalización\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Reducción de Dimensionalidad\n",
        "# !pip install umap-learn\n",
        "from umap import UMAP\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Fuzzy Clustering\n",
        "# !pip install scikit-fuzzy\n",
        "import skfuzzy as fuzz\n",
        "\n",
        "# Metricas\n",
        "from sklearn.metrics import rand_score, adjusted_rand_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBFFIWIWlk_S",
        "outputId": "ecc9eaa4-5bdc-4ba8-ad09-cde6db1fdcf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ifXElQ0blFpk"
      },
      "outputs": [],
      "source": [
        "def seleccionar_muestra(sample_length = None, input_folder=\"outputs/datasets/\", prefijo=\"features_completos_\", sufijo=\".csv.gz\"):\n",
        "    DEFAULT_LENGTH = 15000\n",
        "\n",
        "    clases = [\"Arborio\", \"Basmati\", \"Ipsala\", \"Jasmine\", \"Karacadag\"]\n",
        "\n",
        "    sample_df = pd.DataFrame()\n",
        "    for clase in clases:\n",
        "        path = input_folder+prefijo+clase+sufijo\n",
        "        ids = np.random.choice(np.arange(0,DEFAULT_LENGTH,1), size=sample_length, replace=False)\n",
        "        df = pd.read_csv(path)\n",
        "        df = df.loc[ids, :].reset_index(drop=True)\n",
        "        sample_df = pd.concat([sample_df, df], axis=0)\n",
        "    print(f\"Stratified Sample of {sample_df.shape[0]}\")\n",
        "    return sample_df\n",
        "\n",
        "def seleccionar_features(X:pd.DataFrame, features:str):\n",
        "\n",
        "    # feautres : str puede ser 'morfologicos', 'conv2d', 'both'\n",
        "\n",
        "    default_cols = ['image_id','class_name']\n",
        "    morphological_features = ['area','eccentricity','perimeter', 'orientation','axis_major_length','axis_minor_length']\n",
        "    conv2d_features = [str(i) for i in range(4096)]\n",
        "\n",
        "    if features == \"morfologicos\":\n",
        "        sample_features = X.drop(columns = default_cols + conv2d_features)\n",
        "\n",
        "    elif features == \"conv2d\":\n",
        "        sample_features = X.drop(columns = default_cols + morphological_features)\n",
        "\n",
        "    elif features == \"both\":\n",
        "        sample_features = X.drop(columns = default_cols)\n",
        "    else:\n",
        "        raise ValueError(\"El parámetro 'features' solo acepta 'morfologicos', 'conv2d', 'both'\")\n",
        "    sample_labels = X.class_name.to_list()\n",
        "    return sample_features, sample_labels\n",
        "\n",
        "\n",
        "def hacer_reduccion(X:pd.DataFrame, normalizacion:bool, metodo:str, umap_params:dict):\n",
        "\n",
        "    # method : str puede ser 'pca', 'umap', 'both'\n",
        "    # umap_params: dict {'n_neighbors':int, 'min_dist':float, 'n_components':int, 'metric':str}\n",
        "\n",
        "    if normalizacion:\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "\n",
        "    if (metodo == \"pca\") or (metodo == 'both'):\n",
        "        print(\"Reduction Method PCA\")\n",
        "        DEFAULT_MIN_COMP = 100\n",
        "        ncols = X.shape[1]\n",
        "        n_components = np.min([DEFAULT_MIN_COMP, ncols])\n",
        "\n",
        "        pca = PCA(n_components=n_components)\n",
        "        scaled_pca = pca.fit(X)\n",
        "        X = pca.transform(X)\n",
        "\n",
        "    elif (metodo == 'umap') or (metodo == 'both'):\n",
        "        print(\"Reduction Method UMAP\")\n",
        "        if umap_params:\n",
        "            n_neighbors = umap_params['n_neighbors']\n",
        "            min_dist = umap_params['min_dist']\n",
        "            n_components = umap_params['n_components']\n",
        "            metric = umap_params['metric']\n",
        "            umap = UMAP(n_neighbors=n_neighbors,\n",
        "                        min_dist=min_dist,\n",
        "                        n_components=n_components,\n",
        "                        metric=metric)\n",
        "        else:\n",
        "            umap = UMAP()\n",
        "        X = umap.fit_transform(X)\n",
        "    else:\n",
        "        raise ValueError(\"El parámetro 'metodo' solo acepta  'pca', 'umap', 'both'\")\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def obtener_fuzzy_clusters(X:pd.DataFrame, fuzzy_params:dict):\n",
        "\n",
        "    # fuzzy_params: dict {'n_clusters':int, 'm':int}\n",
        "    DEFAULT_ERROR = 0.001\n",
        "    DEFAULT_MAX_ITER = 1000\n",
        "    if fuzzy_params:\n",
        "        n_clusters = fuzzy_params['n_clusters']\n",
        "        m = fuzzy_params['m']\n",
        "\n",
        "\n",
        "    _, u, _, _, _, _, _ = fuzz.cluster.cmeans(data = X.T,\n",
        "                                                    c = n_clusters,\n",
        "                                                    m = m,\n",
        "                                                    error=DEFAULT_ERROR,\n",
        "                                                    maxiter=DEFAULT_MAX_ITER,\n",
        "                                                    init=None,\n",
        "                                                    seed = 123)\n",
        "\n",
        "    # Plot assigned clusters, for each data point in training set\n",
        "    cluster_membership = np.argmax(u, axis=0)\n",
        "    print(\"Fuzzy Clustering already finish!!!\")\n",
        "    return cluster_membership\n",
        "\n",
        "\n",
        "\n",
        "def make_grid(*args):\n",
        "    return list(itertools.product(*args))\n",
        "\n",
        "def vanDongen(ct):\n",
        "    n2=2*(sum(ct.apply(sum,axis=1)))\n",
        "    sumi = sum(ct.apply(np.max,axis=1))\n",
        "    sumj = sum(ct.apply(np.max,axis=0))\n",
        "    maxsumi = np.max(ct.apply(sum,axis=1))\n",
        "    maxsumj = np.max(ct.apply(sum,axis=0))\n",
        "    vd = (n2 - sumi - sumj)/(n2 - maxsumi - maxsumj)\n",
        "    return vd\n",
        "\n",
        "def cross_tab(Labels_orig, Labels_clust):\n",
        "     '''crea matriz de confusión para evaluar etiquetado\n",
        "     labels_orig  = etiquetas originales - reales\n",
        "     labels_test  = etiquetas halladeas por el algoritmo'''\n",
        "     tmp = pd.DataFrame({'Labels_orig': Labels_orig, 'Labels_clust': Labels_clust})\n",
        "     ct = pd.crosstab(tmp['Labels_clust'],tmp['Labels_orig']) # Create crosstab: ct\n",
        "     rand = rand_score(Labels_orig, Labels_clust)\n",
        "     arand= adjusted_rand_score(Labels_orig, Labels_clust)\n",
        "     vandon =vanDongen(ct)\n",
        "     print(f'RAND score={rand:.4f}, Ajusted RAND={arand:.4f}, vanDongen={vandon:.4f} cantidad_de_muestras={len(Labels_orig):,d}')\n",
        "     return ct, rand, arand, vandon\n",
        "\n",
        "\n",
        "def get_grid_from_dict(grid_params:dict):\n",
        "    n_samples_list = grid_params['n_samples_list']\n",
        "    feature_selection_list = grid_params['feature_selection_list']\n",
        "    reduction_method_list = grid_params['reduction_method_list']\n",
        "    umap_n_neighbors_list = grid_params['umap_params_grid']['n_neighbors']\n",
        "    umap_min_dist_list = grid_params['umap_params_grid']['min_dist']\n",
        "    umap_n_components_list = grid_params['umap_params_grid']['n_components']\n",
        "    umap_metric_list = grid_params['umap_params_grid']['metric']\n",
        "    fuzzy_n_clusters_list = grid_params['fuzzy_params_grid']['n_clusters']\n",
        "    m_list = grid_params['fuzzy_params_grid']['m']\n",
        "\n",
        "    grid = make_grid(n_samples_list, feature_selection_list, reduction_method_list,\n",
        "                     umap_n_neighbors_list, umap_min_dist_list, umap_n_components_list, umap_metric_list,\n",
        "                     fuzzy_n_clusters_list, m_list)\n",
        "\n",
        "    return grid\n",
        "\n",
        "def grid_search(grid_params:dict):\n",
        "\n",
        "    n_samples_list = grid_params['n_samples_list']\n",
        "    feature_selection_list = grid_params['feature_selection_list']\n",
        "    reduction_method_list = grid_params['reduction_method_list']\n",
        "    umap_n_neighbors_list = grid_params['umap_params_grid']['n_neighbors']\n",
        "    umap_min_dist_list = grid_params['umap_params_grid']['min_dist']\n",
        "    umap_n_components_list = grid_params['umap_params_grid']['n_components']\n",
        "    umap_metric_list = grid_params['umap_params_grid']['metric']\n",
        "    fuzzy_n_clusters_list = grid_params['fuzzy_params_grid']['n_clusters']\n",
        "    m_list = grid_params['fuzzy_params_grid']['m']\n",
        "\n",
        "    grid = make_grid(n_samples_list, feature_selection_list, reduction_method_list,\n",
        "                     umap_n_neighbors_list, umap_min_dist_list, umap_n_components_list, umap_metric_list,\n",
        "                     fuzzy_n_clusters_list, m_list)\n",
        "    entries = []\n",
        "    for n, f, r, unn, umd, unc, um, fnc, m in grid:\n",
        "        print(\"Parámetros: \", n, f, r, unn, umd, unc, fnc, m)\n",
        "        start_time1 = time.time()\n",
        "        X = seleccionar_muestra(sample_length=n)\n",
        "        start_time2 = time.time()\n",
        "        sample_features, sample_labels = seleccionar_features(X, features=f)\n",
        "        umap_params = {'n_neighbors':unn, 'min_dist':umd, 'n_components':unc, 'metric':um}\n",
        "        fuzzy_params = {'n_clusters': fnc, 'm': m}\n",
        "        start_time3 = time.time()\n",
        "        reduced_data = hacer_reduccion(X = sample_features, normalizacion=True, metodo=r, umap_params = umap_params)\n",
        "        cluster_membership = obtener_fuzzy_clusters(X = reduced_data, fuzzy_params= fuzzy_params)\n",
        "        _, rand, arand, vandongen = cross_tab(sample_labels, cluster_membership)\n",
        "        #rand = rand_score(labels_true=sample_labels, labels_pred=cluster_membership)\n",
        "        #arand= adjusted_rand_score(labels_true=sample_labels, labels_pred=cluster_membership)\n",
        "        elapsed_time = (time.time() - start_time1)\n",
        "        time_excluding_data_loading = (time.time() - start_time2)\n",
        "        time_excluding_feature_selection = (time.time() - start_time3)\n",
        "        entry = [n*5, f, r, unn, umd, unc, um, fnc, m, rand, arand, vandongen,  elapsed_time, time_excluding_data_loading, time_excluding_feature_selection]\n",
        "#        print(f\"RAND {rand} y ARAND {arand}\")\n",
        "        print(f\"Elapsed time {elapsed_time}\\n\")\n",
        "        entries.append(entry)\n",
        "\n",
        "\n",
        "    output_cols = ['n_samples', 'feature_selection','reduction_method',\n",
        "                   'umap_n_neighbors', 'umap_min_dist','umap_n_components','umap_metric',\n",
        "                   'fuzzy_n_clusters','m', 'rand','arand', 'vandongen',\n",
        "                   'elapsed_time', 'time_excluding_data_loading', 'time_excluding_feature_selection']\n",
        "    return pd.DataFrame(entries, columns=output_cols)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fTNjn9G-lFpl"
      },
      "outputs": [],
      "source": [
        "# En algunos casos tiene seteado parámetros de prueba, hay que ponerle los que están comentados\n",
        "\n",
        "grid_params = {\n",
        "    'n_samples_list' : [5, 10, 100, 1000], #[5, 10, 100, 1000, 5000, 10000]\n",
        "    'feature_selection_list': ['morfologicos'], #['morfologicos', 'conv2d', 'both']\n",
        "    'reduction_method_list': ['pca'], #['pca', 'umap', 'both'],\n",
        "    'umap_params_grid':{\n",
        "        'n_neighbors':[15], #[15, 30, 50, 100]\n",
        "        'min_dist':[0.01], #[0,0, 0.01, 0.1]\n",
        "        'n_components':[4], #[2, 3, 4, 5]\n",
        "        'metric': ['euclidean'],  # ['euclidean', 'manhattan', 'chebyshev', 'cosine']\n",
        "        },\n",
        "    'fuzzy_params_grid': {\n",
        "        'n_clusters': [5], # [2, 3, 4, 5, 6, 7]\n",
        "        'm': [2]\n",
        "    }\n",
        "}\n",
        "\n",
        "grid = get_grid_from_dict(grid_params)\n",
        "# result_grid_search = grid_search(grid_params=grid_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "em9owyFhrAph"
      },
      "outputs": [],
      "source": [
        "#Fijamos la cantidad de hilos (threadings)\n",
        "n_threads = 4\n",
        "\n",
        "\n",
        "#Vamos a determinar la cantidad de elementos que va a tener que analizar cada thread.\n",
        "p=len(grid)//n_threads # Acá hacemos división entera para que me divida la cantidad de elementos en n partes iguales.\n",
        "inicios = []\n",
        "fines = []\n",
        "inicio=0\n",
        "fin=p\n",
        "\n",
        "\n",
        "#Acá vamos a crear los inicios y los fines.\n",
        "for i in range(n_threads):\n",
        "  inicios.append(inicio)\n",
        "  fines.append(fin)\n",
        "  inicio= inicio + p\n",
        "  fin= fin + p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pB1LayWesQVD"
      },
      "outputs": [],
      "source": [
        "entries = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def worker_thread(inicio, fin):\n",
        "\n",
        "  for i in tqdm(range(inicio, fin)):\n",
        "\n",
        "    n, f, r, unn, umd, unc, um, fnc, m = grid[i]\n",
        "    print(\"Parámetros: \", n, f, r, unn, umd, unc, fnc, m)\n",
        "    start_time1 = time.time()\n",
        "    X = seleccionar_muestra(sample_length=n, input_folder=\"outputs/datasets/\")\n",
        "    start_time2 = time.time()\n",
        "    sample_features, sample_labels = seleccionar_features(X, features=f)\n",
        "    umap_params = {'n_neighbors': unn, 'min_dist': umd, 'n_components': unc, 'metric': um}\n",
        "    fuzzy_params = {'n_clusters': fnc, 'm': m}\n",
        "    start_time3 = time.time()\n",
        "    reduced_data = hacer_reduccion(X=sample_features, normalizacion=True, metodo=r, umap_params=umap_params)\n",
        "    cluster_membership = obtener_fuzzy_clusters(X=reduced_data, fuzzy_params=fuzzy_params)\n",
        "    _, rand, arand, vandongen = cross_tab(sample_labels, cluster_membership)\n",
        "    elapsed_time = (time.time() - start_time1)\n",
        "    time_excluding_data_loading = (time.time() - start_time2)\n",
        "    time_excluding_feature_selection = (time.time() - start_time3)\n",
        "    entry = [n*5, f, r, unn, umd, unc, um, fnc, m, rand, arand, vandongen,  elapsed_time, time_excluding_data_loading, time_excluding_feature_selection]\n",
        "    print(f\"Elapsed time {elapsed_time}\\n\")\n",
        "    entries.append(entry)\n",
        "\n",
        "  return entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRVlQZ9ktfC-",
        "outputId": "9a26bc2c-1fb2-40a6-d5ff-b3e431273f8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[A\n",
            "\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros:  5 morfologicos pca 15 0.01 4 5 2\n",
            "Parámetros:  10 morfologicos pca 15 0.01 4 5 2\n",
            "Parámetros:  100 morfologicos pca 15 0.01 4 5 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros:  1000 morfologicos pca 15 0.01 4 5 2\n",
            "Stratified Sample of 500\n",
            "Reduction Method PCA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [04:54<00:00, 294.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fuzzy Clustering already finish!!!\n",
            "RAND score=0.8855, Ajusted RAND=0.6413, vanDongen=0.2697 cantidad_de_muestras=500\n",
            "Elapsed time 294.3625211715698\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [04:59<00:00, 299.73s/it]\n",
            "100%|██████████| 1/1 [04:59<00:00, 299.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratified Sample of 50\n",
            "Reduction Method PCA\n",
            "Stratified Sample of 25\n",
            "Reduction Method PCA\n",
            "Fuzzy Clustering already finish!!!\n",
            "RAND score=0.9584, Ajusted RAND=0.8614, vanDongen=0.0759 cantidad_de_muestras=50\n",
            "Elapsed time 299.71495246887207\n",
            "\n",
            "Fuzzy Clustering already finish!!!\n",
            "RAND score=0.9000, Ajusted RAND=0.6457, vanDongen=0.2051 cantidad_de_muestras=25\n",
            "Elapsed time 299.7327060699463\n",
            "\n",
            "Stratified Sample of 5000\n",
            "Reduction Method PCA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [05:00<00:00, 300.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fuzzy Clustering already finish!!!\n",
            "RAND score=0.8806, Ajusted RAND=0.6281, vanDongen=0.2728 cantidad_de_muestras=5,000\n",
            "Elapsed time 300.1059010028839\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "\n",
        "threads=[]\n",
        "for i in range(len(inicios)):\n",
        "  t=threading.Thread(target=worker_thread, args=(inicios[i], fines[i],))\n",
        "  threads.append(t)\n",
        "  t.start()\n",
        "\n",
        "for t in threads:\n",
        "  t.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oUvKLI2Xt2Vl"
      },
      "outputs": [],
      "source": [
        "output_cols = ['n_samples', 'feature_selection', 'reduction_method',\n",
        "                   'umap_n_neighbors', 'umap_min_dist', 'umap_n_components', 'umap_metric',\n",
        "                   'fuzzy_n_clusters', 'm', 'rand', 'arand', 'vandongen',\n",
        "                   'elapsed_time', 'time_excluding_data_loading', 'time_excluding_feature_selection']\n",
        "df= pd.DataFrame(entries, columns=output_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5XcUuKx6vY09",
        "outputId": "290c9fd2-1b4d-46c5-84b8-4557280b1a1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_samples</th>\n",
              "      <th>feature_selection</th>\n",
              "      <th>reduction_method</th>\n",
              "      <th>umap_n_neighbors</th>\n",
              "      <th>umap_min_dist</th>\n",
              "      <th>umap_n_components</th>\n",
              "      <th>umap_metric</th>\n",
              "      <th>fuzzy_n_clusters</th>\n",
              "      <th>m</th>\n",
              "      <th>rand</th>\n",
              "      <th>arand</th>\n",
              "      <th>vandongen</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>time_excluding_data_loading</th>\n",
              "      <th>time_excluding_feature_selection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>morfologicos</td>\n",
              "      <td>pca</td>\n",
              "      <td>15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.885459</td>\n",
              "      <td>0.641257</td>\n",
              "      <td>0.269720</td>\n",
              "      <td>294.362521</td>\n",
              "      <td>0.591696</td>\n",
              "      <td>0.585618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>morfologicos</td>\n",
              "      <td>pca</td>\n",
              "      <td>15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.958367</td>\n",
              "      <td>0.861405</td>\n",
              "      <td>0.075949</td>\n",
              "      <td>299.714952</td>\n",
              "      <td>0.042826</td>\n",
              "      <td>0.039405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>morfologicos</td>\n",
              "      <td>pca</td>\n",
              "      <td>15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.645669</td>\n",
              "      <td>0.205128</td>\n",
              "      <td>299.732706</td>\n",
              "      <td>0.047122</td>\n",
              "      <td>0.034135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5000</td>\n",
              "      <td>morfologicos</td>\n",
              "      <td>pca</td>\n",
              "      <td>15</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.880629</td>\n",
              "      <td>0.628119</td>\n",
              "      <td>0.272750</td>\n",
              "      <td>300.105901</td>\n",
              "      <td>0.252046</td>\n",
              "      <td>0.248515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_samples feature_selection reduction_method  umap_n_neighbors  \\\n",
              "0        500      morfologicos              pca                15   \n",
              "1         50      morfologicos              pca                15   \n",
              "2         25      morfologicos              pca                15   \n",
              "3       5000      morfologicos              pca                15   \n",
              "\n",
              "   umap_min_dist  umap_n_components umap_metric  fuzzy_n_clusters  m  \\\n",
              "0           0.01                  4   euclidean                 5  2   \n",
              "1           0.01                  4   euclidean                 5  2   \n",
              "2           0.01                  4   euclidean                 5  2   \n",
              "3           0.01                  4   euclidean                 5  2   \n",
              "\n",
              "       rand     arand  vandongen  elapsed_time  time_excluding_data_loading  \\\n",
              "0  0.885459  0.641257   0.269720    294.362521                     0.591696   \n",
              "1  0.958367  0.861405   0.075949    299.714952                     0.042826   \n",
              "2  0.900000  0.645669   0.205128    299.732706                     0.047122   \n",
              "3  0.880629  0.628119   0.272750    300.105901                     0.252046   \n",
              "\n",
              "   time_excluding_feature_selection  \n",
              "0                          0.585618  \n",
              "1                          0.039405  \n",
              "2                          0.034135  \n",
              "3                          0.248515  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
