{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachengue/fundar/python_projects/unsupervised-rice-image-segmentation/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-10 18:52:11.170422: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-10 18:52:11.173564: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-10 18:52:11.221566: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-10 18:52:11.222650: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-10 18:52:11.859983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"is_categorical_dtype\")\n",
    "warnings.filterwarnings(\"ignore\", \"use_inf_as_na\")\n",
    "\n",
    "# Normalización\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reducción de Dimensionalidad\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Clustering\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import rand_score, adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_sse_kmedoids(KM,d):\n",
    "  se = []\n",
    "  for i in range(0,KM.n_clusters):\n",
    "    se.append(sum(d[KM.medoid_indices_[i],KM.labels_==i]**2))\n",
    "  return sum(se)\n",
    "\n",
    "def cross_tab(Labels_orig, Labels_clust):\n",
    "    '''crea matriz de confusión para evaluar etiquetado\n",
    "    labels_orig  = etiquetas originales - reales\n",
    "    labels_test  = etiquetas halladeas por el algoritmo'''\n",
    "    tmp = pd.DataFrame({'Labels_orig': Labels_orig, 'Labels_clust': Labels_clust})\n",
    "    ct = pd.crosstab(tmp['Labels_clust'],tmp['Labels_orig']) # Create crosstab: ct\n",
    "    rand = rand_score(Labels_orig, Labels_clust)\n",
    "    arand= adjusted_rand_score(Labels_orig, Labels_clust)\n",
    "    print(f'RAND score={rand:.4f}, Ajusted RAND={arand:.4f}, cantidad_de_muestras={len(Labels_orig):,d}')\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arborio (3000, 4104)\n",
      "Basmati (6000, 4104)\n",
      "Ipsala (9000, 4104)\n",
      "Jasmine (12000, 4104)\n",
      "Karacadag (15000, 4104)\n"
     ]
    }
   ],
   "source": [
    "# Selecciono N filas de cada archivo input. \n",
    "\n",
    "DEFAULT_LENGTH = 15000 \n",
    "SAMPLE_LENGTH = 3000\n",
    "\n",
    "prefijo = \"features_completos_\"\n",
    "sufijo = \".csv.gz\"\n",
    "clases = [\"Arborio\", \"Basmati\", \"Ipsala\", \"Jasmine\", \"Karacadag\"]\n",
    "input_folder = \"output/datasets/\"\n",
    "input_paths = [input_folder+prefijo+c+sufijo for c in clases]\n",
    "\n",
    "\n",
    "sample_df = pd.DataFrame()\n",
    "for clase in clases:\n",
    "    path = input_folder+prefijo+clase+sufijo\n",
    "    ids = np.random.choice(np.arange(0,DEFAULT_LENGTH,1), size=SAMPLE_LENGTH, replace=False)\n",
    "    df = pd.read_csv(path) \n",
    "    df = df.loc[ids, :].reset_index(drop=True)\n",
    "    sample_df = pd.concat([sample_df, df], axis=0)\n",
    "    print(clase, sample_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cols = ['image_id','class_name']\n",
    "morphological_features = ['area','eccentricity','perimeter', 'orientation','axis_major_length','axis_minor_length']\n",
    "conv2d_features = [str(i) for i in range(4096)]\n",
    "\n",
    "sample_features = sample_df.drop(columns = default_cols + morphological_features)\n",
    "sample_labels = sample_df.class_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso PCA\n",
    "\n",
    "ncols = sample_features.shape[1]\n",
    "n_components = np.min([100, ncols])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(sample_features)\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "scaled_pca = pca.fit(scaled)\n",
    "Xpca = pca.transform(scaled)\n",
    "\n",
    "exp_var = scaled_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM_meta=KMedoids(n_clusters=4,metric='precomputed',init='k-medoids++').fit(d_meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
